{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, Namespace, Literal\n",
    "from rdflib.namespace import SKOS\n",
    "import requests\n",
    "\n",
    "YSO = Namespace('http://www.yso.fi/onto/yso/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 88.10392665863037\n"
     ]
    }
   ],
   "source": [
    "# Load YSA, YSO and YSO Places - this may take a few minutes\n",
    "# The parsing is done in parallel on multiple CPUs, to save some time\n",
    "\n",
    "import time\n",
    "starttime = time.time()\n",
    "import multiprocessing\n",
    "\n",
    "def load_graph(url):\n",
    "    g = Graph()\n",
    "    g.load(url)\n",
    "    return g\n",
    "\n",
    "urls = [\n",
    "    'http://api.finto.fi/rest/v1/ysa/data',\n",
    "    'http://api.finto.fi/rest/v1/yso/data',\n",
    "    'http://api.finto.fi/rest/v1/yso-paikat/data'\n",
    "]\n",
    "\n",
    "# create a pool of processes and parse each vocabulary in a separate process\n",
    "with multiprocessing.Pool(processes=len(urls)) as pool:\n",
    "    ysa, yso, ysop = pool.map(load_graph, urls)\n",
    "\n",
    "elapsed = time.time() - starttime\n",
    "print(\"Time taken:\", elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ac0b9293-18ab-4eee-ab0b-ddee87fb1a1c a5ae67f3-9d8f-4458-af1d-80a1b8d3c48d\n"
     ]
    }
   ],
   "source": [
    "URLBASE = 'https://jyx2.jyu.fi'\n",
    "\n",
    "doctoral_uuid = requests.post(URLBASE + '/rest/collections/find-collection',\n",
    "                              data='Väitöskirjat'.encode('UTF-8')).json()['uuid']\n",
    "masters_uuid = requests.post(URLBASE + '/rest/collections/find-collection',\n",
    "                             data='Pro gradu -tutkielmat'.encode('UTF-8')).json()['uuid']\n",
    "print(doctoral_uuid, masters_uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "\n",
    "LABELLANG = {\n",
    "    'fin': 'fi',\n",
    "    'swe': 'sv',\n",
    "    'eng': 'en'\n",
    "}\n",
    "\n",
    "MIN_SUBJECTS = 3\n",
    "\n",
    "def handle(doc):\n",
    "    return doc['handle']\n",
    "\n",
    "def doc_id(doc):\n",
    "    return handle(doc).split('/')[-1] # use only the last part since the first part is always 123456789\n",
    "\n",
    "def pdf_url(doc):\n",
    "    for bitstream in doc['bitstreams']:\n",
    "        if bitstream['bundleName'] == 'ORIGINAL' and bitstream['mimeType'] == 'application/pdf':\n",
    "            return URLBASE + '/dspace/bitstream/handle/' + handle(doc) + '/' + bitstream['name']\n",
    "\n",
    "def issued(doc):\n",
    "    for mdfld in doc['metadata']:\n",
    "        if mdfld['key'] == 'dc.date.issued':\n",
    "            return mdfld['value']\n",
    "\n",
    "def language(doc):\n",
    "    for mdfld in doc['metadata']:\n",
    "        if mdfld['element'] == 'language':\n",
    "            return mdfld['value']\n",
    "\n",
    "def ysa_subjects(doc):\n",
    "    subjs = []\n",
    "    for mdfld in doc['metadata']:\n",
    "        if mdfld['key'] == 'dc.subject.ysa':\n",
    "            subjs.append(mdfld['value'])\n",
    "    return subjs\n",
    "\n",
    "def ysalabel_to_ysauri(label):\n",
    "    # prefLabel\n",
    "    uri = ysa.value(None, SKOS.prefLabel, Literal(label, \"fi\"))\n",
    "    if uri is not None:\n",
    "        return uri\n",
    "    # altLabel\n",
    "    uri = ysa.value(None, SKOS.altLabel, Literal(label, \"fi\"))\n",
    "    if uri is not None:\n",
    "        return uri\n",
    "    return None\n",
    "\n",
    "def ysauri_to_ysouris(ysauri):\n",
    "    if ysauri is None:\n",
    "        return []\n",
    "    return [uri for prop in (SKOS.closeMatch, SKOS.exactMatch)\n",
    "                for uri in ysa.objects(ysauri, prop)\n",
    "                if uri.startswith(YSO)]\n",
    "\n",
    "def ysouri_label(uri, lang):\n",
    "    for voc in (yso, ysop):\n",
    "        labels = voc.preferredLabel(uri, lang=lang)\n",
    "        if len(labels) > 0:\n",
    "            return labels[0][1]\n",
    "\n",
    "def to_yso_subjects(ysalabels, lang):\n",
    "    yso_uris_labels = []\n",
    "    for ysalabel in ysalabels:\n",
    "        ysauri = ysalabel_to_ysauri(ysalabel)\n",
    "        if ysauri is None:\n",
    "            continue # not found in YSA, skip\n",
    "        for ysouri in ysauri_to_ysouris(ysauri):\n",
    "            ysolabel = ysouri_label(ysouri, lang)\n",
    "            if ysolabel is not None:\n",
    "                yso_uris_labels.append((ysouri, str(ysolabel)))\n",
    "    return yso_uris_labels\n",
    "\n",
    "def fetch_items(url):\n",
    "    req = requests.get(url)\n",
    "    data = req.json()\n",
    "    return data['items']\n",
    "\n",
    "def extract_doc_metadata(items):\n",
    "    docs = []\n",
    "    for doc in items:\n",
    "        lang = language(doc)\n",
    "        if lang not in LABELLANG:\n",
    "            continue # skip doc if the language is not in YSO\n",
    "        subjects = ysa_subjects(doc)\n",
    "        yso_subjects = to_yso_subjects(ysa_subjects(doc), LABELLANG[lang])\n",
    "        if len(yso_subjects) < MIN_SUBJECTS:\n",
    "            continue # skip doc if there are not enough YSO subjects\n",
    "        pdfurl = pdf_url(doc)\n",
    "        if pdfurl is None:\n",
    "            continue # skip if we didn't find a PDF URL\n",
    "        docs.append((doc_id(doc), lang, issued(doc), pdfurl, yso_subjects))\n",
    "    return docs\n",
    "\n",
    "def store_doc(doctype, doc):\n",
    "    doc_id, lang, iss, url, subjects = doc\n",
    "    if not os.path.exists(lang):\n",
    "        os.mkdir(lang)\n",
    "    filenamebase = \"%s-%s-%s\" % (iss, doctype, doc_id)\n",
    "    with open(os.path.join(lang, filenamebase + '.url'), 'w') as urlfile:\n",
    "        print(url, file=urlfile)\n",
    "    with open(os.path.join(lang, filenamebase + '.tsv'), 'w') as tsvfile:\n",
    "        for uri, label in subjects:\n",
    "            print(\"<%s>\\t%s\" % (uri, label), file=tsvfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Master's theses for year 2010, page 0: 100 found, of which 76 were stored.\n",
      "Fetching Master's theses for year 2010, page 1: 100 found, of which 77 were stored.\n",
      "Fetching Master's theses for year 2010, page 2: 100 found, of which 83 were stored.\n",
      "Fetching Master's theses for year 2010, page 3: 100 found, of which 74 were stored.\n",
      "Fetching Master's theses for year 2010, page 4: 100 found, of which 79 were stored.\n",
      "Fetching Master's theses for year 2010, page 5: 98 found, of which 80 were stored.\n",
      "Fetching Doctoral theses for year 2010, page 0: 100 found, of which 86 were stored.\n",
      "Fetching Doctoral theses for year 2010, page 1: 12 found, of which 8 were stored.\n",
      "Fetching Master's theses for year 2011, page 0: 100 found, of which 74 were stored.\n",
      "Fetching Master's theses for year 2011, page 1: 100 found, of which 88 were stored.\n",
      "Fetching Master's theses for year 2011, page 2: 100 found, of which 83 were stored.\n",
      "Fetching Master's theses for year 2011, page 3: 100 found, of which 75 were stored.\n",
      "Fetching Master's theses for year 2011, page 4: 100 found, of which 77 were stored.\n",
      "Fetching Master's theses for year 2011, page 5: 100 found, of which 82 were stored.\n",
      "Fetching Master's theses for year 2011, page 6: 100 found, of which 80 were stored.\n",
      "Fetching Master's theses for year 2011, page 7: 74 found, of which 59 were stored.\n",
      "Fetching Doctoral theses for year 2011, page 0: 100 found, of which 87 were stored.\n",
      "Fetching Doctoral theses for year 2011, page 1: 32 found, of which 27 were stored.\n",
      "Fetching Master's theses for year 2012, page 0: 100 found, of which 83 were stored.\n",
      "Fetching Master's theses for year 2012, page 1: 100 found, of which 85 were stored.\n",
      "Fetching Master's theses for year 2012, page 2: 100 found, of which 88 were stored.\n",
      "Fetching Master's theses for year 2012, page 3: 100 found, of which 88 were stored.\n",
      "Fetching Master's theses for year 2012, page 4: 100 found, of which 82 were stored.\n",
      "Fetching Master's theses for year 2012, page 5: 100 found, of which 77 were stored.\n",
      "Fetching Master's theses for year 2012, page 6: 100 found, of which 87 were stored.\n",
      "Fetching Master's theses for year 2012, page 7: 100 found, of which 90 were stored.\n",
      "Fetching Master's theses for year 2012, page 8: 21 found, of which 19 were stored.\n",
      "Fetching Doctoral theses for year 2012, page 0: 100 found, of which 92 were stored.\n",
      "Fetching Doctoral theses for year 2012, page 1: 20 found, of which 18 were stored.\n",
      "Fetching Master's theses for year 2013, page 0: 100 found, of which 82 were stored.\n",
      "Fetching Master's theses for year 2013, page 1: 100 found, of which 87 were stored.\n",
      "Fetching Master's theses for year 2013, page 2: 100 found, of which 82 were stored.\n",
      "Fetching Master's theses for year 2013, page 3: 100 found, of which 89 were stored.\n",
      "Fetching Master's theses for year 2013, page 4: 100 found, of which 89 were stored.\n",
      "Fetching Master's theses for year 2013, page 5: 100 found, of which 82 were stored.\n",
      "Fetching Master's theses for year 2013, page 6: 100 found, of which 90 were stored.\n",
      "Fetching Master's theses for year 2013, page 7: 100 found, of which 73 were stored.\n",
      "Fetching Master's theses for year 2013, page 8: 100 found, of which 89 were stored.\n",
      "Fetching Master's theses for year 2013, page 9: 64 found, of which 57 were stored.\n",
      "Fetching Doctoral theses for year 2013, page 0: 100 found, of which 96 were stored.\n",
      "Fetching Doctoral theses for year 2013, page 1: 44 found, of which 40 were stored.\n",
      "Fetching Master's theses for year 2014, page 0: 100 found, of which 85 were stored.\n",
      "Fetching Master's theses for year 2014, page 1: 100 found, of which 90 were stored.\n",
      "Fetching Master's theses for year 2014, page 2: 100 found, of which 87 were stored.\n",
      "Fetching Master's theses for year 2014, page 3: 100 found, of which 87 were stored.\n",
      "Fetching Master's theses for year 2014, page 4: 100 found, of which 86 were stored.\n",
      "Fetching Master's theses for year 2014, page 5: 100 found, of which 84 were stored.\n",
      "Fetching Master's theses for year 2014, page 6: 100 found, of which 88 were stored.\n",
      "Fetching Master's theses for year 2014, page 7: 100 found, of which 86 were stored.\n",
      "Fetching Master's theses for year 2014, page 8: 100 found, of which 86 were stored.\n",
      "Fetching Master's theses for year 2014, page 9: 100 found, of which 85 were stored.\n",
      "Fetching Master's theses for year 2014, page 10: 59 found, of which 51 were stored.\n",
      "Fetching Doctoral theses for year 2014, page 0: 100 found, of which 95 were stored.\n",
      "Fetching Doctoral theses for year 2014, page 1: 42 found, of which 37 were stored.\n",
      "Fetching Master's theses for year 2015, page 0: 100 found, of which 86 were stored.\n",
      "Fetching Master's theses for year 2015, page 1: 100 found, of which 81 were stored.\n",
      "Fetching Master's theses for year 2015, page 2: 100 found, of which 80 were stored.\n",
      "Fetching Master's theses for year 2015, page 3: 100 found, of which 79 were stored.\n",
      "Fetching Master's theses for year 2015, page 4: 100 found, of which 81 were stored.\n",
      "Fetching Master's theses for year 2015, page 5: 100 found, of which 78 were stored.\n",
      "Fetching Master's theses for year 2015, page 6: 100 found, of which 80 were stored.\n",
      "Fetching Master's theses for year 2015, page 7: 100 found, of which 82 were stored.\n",
      "Fetching Master's theses for year 2015, page 8: 100 found, of which 89 were stored.\n",
      "Fetching Master's theses for year 2015, page 9: 100 found, of which 83 were stored.\n",
      "Fetching Master's theses for year 2015, page 10: 100 found, of which 81 were stored.\n",
      "Fetching Master's theses for year 2015, page 11: 27 found, of which 18 were stored.\n",
      "Fetching Doctoral theses for year 2015, page 0: 100 found, of which 96 were stored.\n",
      "Fetching Doctoral theses for year 2015, page 1: 44 found, of which 43 were stored.\n",
      "Fetching Master's theses for year 2016, page 0: 100 found, of which 82 were stored.\n",
      "Fetching Master's theses for year 2016, page 1: 100 found, of which 82 were stored.\n",
      "Fetching Master's theses for year 2016, page 2: 100 found, of which 83 were stored.\n",
      "Fetching Master's theses for year 2016, page 3: 100 found, of which 71 were stored.\n",
      "Fetching Master's theses for year 2016, page 4: 100 found, of which 80 were stored.\n",
      "Fetching Master's theses for year 2016, page 5: 100 found, of which 85 were stored.\n",
      "Fetching Master's theses for year 2016, page 6: 100 found, of which 78 were stored.\n",
      "Fetching Master's theses for year 2016, page 7: 100 found, of which 78 were stored.\n",
      "Fetching Master's theses for year 2016, page 8: 100 found, of which 82 were stored.\n",
      "Fetching Master's theses for year 2016, page 9: 100 found, of which 75 were stored.\n",
      "Fetching Master's theses for year 2016, page 10: 100 found, of which 75 were stored.\n",
      "Fetching Master's theses for year 2016, page 11: 100 found, of which 89 were stored.\n",
      "Fetching Master's theses for year 2016, page 12: 69 found, of which 47 were stored.\n",
      "Fetching Doctoral theses for year 2016, page 0: 100 found, of which 98 were stored.\n",
      "Fetching Doctoral theses for year 2016, page 1: 49 found, of which 49 were stored.\n",
      "Fetching Master's theses for year 2017, page 0: 100 found, of which 78 were stored.\n",
      "Fetching Master's theses for year 2017, page 1: 100 found, of which 77 were stored.\n",
      "Fetching Master's theses for year 2017, page 2: 100 found, of which 77 were stored.\n",
      "Fetching Master's theses for year 2017, page 3: 100 found, of which 79 were stored.\n",
      "Fetching Master's theses for year 2017, page 4: 100 found, of which 75 were stored.\n",
      "Fetching Master's theses for year 2017, page 5: 100 found, of which 81 were stored.\n",
      "Fetching Master's theses for year 2017, page 6: 100 found, of which 74 were stored.\n",
      "Fetching Master's theses for year 2017, page 7: 100 found, of which 80 were stored.\n",
      "Fetching Master's theses for year 2017, page 8: 100 found, of which 83 were stored.\n",
      "Fetching Master's theses for year 2017, page 9: 100 found, of which 77 were stored.\n",
      "Fetching Master's theses for year 2017, page 10: 100 found, of which 79 were stored.\n",
      "Fetching Master's theses for year 2017, page 11: 100 found, of which 80 were stored.\n",
      "Fetching Master's theses for year 2017, page 12: 27 found, of which 18 were stored.\n",
      "Fetching Doctoral theses for year 2017, page 0: 100 found, of which 94 were stored.\n",
      "Fetching Doctoral theses for year 2017, page 1: 32 found, of which 31 were stored.\n",
      "Total documents stored: 7401 elapsed time: 2614.1496756076813\n"
     ]
    }
   ],
   "source": [
    "urlpat = URLBASE + '/rest/filtered-items?limit=%d&offset=%d&query_field[]=dc.date.issued&query_op[]=equals&query_val[]=%d&collSel[]=%s&expand=parentCollection,metadata,bitstreams'\n",
    "\n",
    "PAGESIZE=100\n",
    "\n",
    "starttime = time.time()\n",
    "total = 0\n",
    "for year in range(2010, 2018):\n",
    "    for name, uuid in ((\"Master's\", masters_uuid), (\"Doctoral\", doctoral_uuid)):\n",
    "        for page in range(20):\n",
    "            print(\"Fetching %s theses for year %d, page %d: \" % (name, year, page), end='')\n",
    "            doctype = name[0] # \"M\" or \"D\"\n",
    "            url = urlpat % (PAGESIZE, page * PAGESIZE, year, uuid)\n",
    "            items = fetch_items(url)\n",
    "            docs = extract_doc_metadata(items)\n",
    "            print(\"%d found, of which %d were stored.\" % (len(items), len(docs)))\n",
    "            total += len(docs)\n",
    "            for doc in docs:\n",
    "                store_doc(doctype, doc)\n",
    "            if len(items) < PAGESIZE:\n",
    "                break # no more results expected\n",
    "\n",
    "elapsed = time.time() - starttime\n",
    "print(\"Total documents stored:\", total, \"elapsed time:\", elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
